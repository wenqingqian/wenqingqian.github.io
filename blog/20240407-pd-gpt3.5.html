

<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Blog</title>
	<link rel="icon" href="../icon/appletree.png" type="image/png">
	<link href="../render_base/fonts.css" rel="stylesheet">
	<link href="../render_base/blog.css" rel="stylesheet">
	<link href="../render_base/style_base.css" rel="stylesheet">
	<link href="../render_base/style_chinese.css" rel="stylesheet">
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Ma+Shan+Zheng&family=ZCOOL+XiaoWei&display=swap" rel="stylesheet">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
	<link href="../render_base/sidebar.css" rel="stylesheet">
	<link href="../render_base/common.css" rel="stylesheet">
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<main>
<div class='disp-toc-header'>
<h1>[GPT3.5] Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!</h1><h2 style="font-family: 'ZCOOL XiaoWei', regular;"> 2024-4-7</h2>
</div><p><a href="https://arxiv.org/pdf/2303.08559.pdf">论文原文</a></p>
<section>
<h1>intro</h1>
<p>本文回答以下四个问题:</p>
<ul>
<li>LLMs在few-shot IE (Information Extraction) 任务中是否比Small Language Models(SLMs)表现更好</li>
<li>更多的标注数据能否增强LLMs和SLMs</li>
<li>如何取舍金钱和时间成本</li>
<li>LLMs和SLMs是否分别擅长处理不同类别的样本</li>
</ul>
<p>实验结果显示:</p>
<ul>
<li>只有当标注数据数量受限时(每个标签的类别和样本稀缺) LLMs 比 SLMs 好 </li>
<p style="margin-bottom: 0em;">当样本增多时, SLMs超过LLMs, 可能的原因是:</p>
<ul>
<li>由于ICL (in-context-learning) 最大输入长度限制, 只有一小部分样本可以用作prompt demos</li>
<li>标签类别增加导致 prompt 中每个标签的样本数减少</li>
</ul>
<li>LLMs比finetuning SLMs 有更高的推理延迟, 尤其是当 ICL 的 demos 很长</li>
<li>LLMs更适合 hard samples (LLMs有更多的知识) 而不是 easy samples (SLMs 经过微调)</li>
</ul>
</section>
<section>
<h1>filter-then-rerank</h1>
<img src="../generator/raw_file/blog_markdown/./pic/llmpost/ftr/framework.png" style="display: block; margin: 0 auto;width: 75%;" alt="err! email me if you need">
<figure><figcaption>overall architecture of our adaptive filter-then-rerank paradigm</figcaption></figure><p>基于上述实验结果(总结):</p>
<ul>
<li>(1)表述了在更多训练样本和复杂模式下的SLMs IE效果更好</li>
<li>(2)表述了SLMs更轻量级</li>
</ul>
<p>本文提出自适应 filter-then-rerank 框架, 融合了SLMs和LLMs, 其中:</p>
<ul>
<li>SLMs作为filter</li>
<li>LLMs作为reranker</li>
</ul>
<p>SLMs提取N个可能性最高的候选, 对于无法顺利处理的样本, LLMs重新排序这N个标签并生成结果</p>
<p>具体的rerank过程:</p>
<ul>
<li>使用类似如下多项选择题式的 prompt模板</li>
<li>具体的, 这个示例模板描述两个"entity"之间具有"label"关系, 生成选项后由LLMs做出选择</li>
</ul>
<img src="../generator/raw_file/blog_markdown/./pic/llmpost/ftr/prompt_temp.png" style="width: 40%;" alt="err! email me if you need">
<img src="../generator/raw_file/blog_markdown/./pic/llmpost/ftr/example.png" style="width: 40%;" alt="err! email me if you need">
<figure><figcaption>other example</figcaption></figure><p>这种模板的优点在于:</p>
<ul>
<li>缩小标签范围</li>
<li>降低IE任务复杂度, 因为LLMs对这种格式更熟悉</li>
</ul>
</section>

	
	<div class="settings-menu">
		<button class="settings-button">Control</button>
		<div class="settings-options">
			<a class="settings-button" href="../index.html">home</a>
			<button id="color_mode_button" class="settings-button" onclick="toggleDarkMode()"> dark</button>
			<a style="color: var(--basic-black);">width <button id="adjustWidth-add" class="settings-inner-button">+</button> / <button id="adjustWidth-sub" class="settings-inner-button">-</button></a>
			<a class="settings-button" href="../blog.html">back to blog</a>
		</div>
	</div>
</main>


<script src="../render_base/sidebar.js"></script> 
<script src="../render_base/common.js"></script> 

</body>
</html>

