---
title: GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints
date: 2024-4-5
category: llm paper reading
description:
ps:
language: english
type: html
redirect:
---

<a href="https://arxiv.org/pdf/2305.13245.pdf">论文原文</a>

# intro

two contributions:

- method for converting MHA checkpoint to MQA checkpoint
- propose GQA: an interpolation between MHA and MQA

# Approach

## checkpoint convert

![60](./pic/llmpost/gqa/1.png)

apply mean pool instead of selecting a single kv or randomly initializing

## GQA

![70](./pic/llmpost/gqa/2.png)

The quality of GQA is close to MHA when its speed is close to MQA

It cant be applied to encoder which is computed in parallel
